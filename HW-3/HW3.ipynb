{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5j26h9NIXad",
        "outputId": "2c37fc96-903f-43de-d0ae-14c30dd69db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating for Digits Dataset\n",
            "Perceptron:\n",
            "  This is Training Accuracy: 0.9687\n",
            "  This is Testing Accuracy: 0.9500\n",
            "  This is Training Time: 2.9102 sec\n",
            "  This is Best Parameter: {'model__alpha': 0.0001, 'model__eta0': 0.01}\n",
            "\n",
            "Logistic Regression:\n",
            "  This is Training Accuracy: 0.9889\n",
            "  This is Testing Accuracy: 0.9667\n",
            "  This is Training Time: 5.9546 sec\n",
            "  This is Best Parameter: {'model__C': 1}\n",
            "\n",
            "Linear SVM:\n",
            "  This is Training Accuracy: 0.9965\n",
            "  This is Testing Accuracy: 0.9750\n",
            "  This is Training Time: 1.1856 sec\n",
            "  This is Best Parameter: {'model__C': 0.1}\n",
            "\n",
            "Non-linear SVM (RBF):\n",
            "  This is Training Accuracy: 1.0000\n",
            "  This is Testing Accuracy: 0.9806\n",
            "  This is Training Time: 2.4123 sec\n",
            "  This is Best Parameter: {'model__C': 10}\n",
            "\n",
            "Decision Tree:\n",
            "  This is Training Accuracy: 1.0000\n",
            "  This is Testing Accuracy: 0.8583\n",
            "  This is Training Time: 0.0208 sec\n",
            "  This is Best Parameter: Not Required\n",
            "\n",
            "KNN:\n",
            "  This is Training Accuracy: 0.9868\n",
            "  This is Testing Accuracy: 0.9750\n",
            "  This is Training Time: 0.0035 sec\n",
            "  This is Best Parameter: Not Required\n",
            "\n",
            "\n",
            "Evaluating for Iris Dataset\n",
            "Logistic Regression:\n",
            "  This is Training Accuracy: 0.9832\n",
            "  This is Testing Accuracy: 0.9000\n",
            "  This is Training Time: 0.0833 sec\n",
            "  This is Best Parameter: {'model__C': 100}\n",
            "\n",
            "Non-linear SVM (RBF):\n",
            "  This is Training Accuracy: 0.9832\n",
            "  This is Testing Accuracy: 0.9333\n",
            "  This is Training Time: 0.0679 sec\n",
            "  This is Best Parameter: {'model__C': 1}\n",
            "\n",
            "Decision Tree:\n",
            "  This is Training Accuracy: 1.0000\n",
            "  This is Testing Accuracy: 0.9000\n",
            "  This is Training Time: 0.0015 sec\n",
            "  This is Best Parameter: Not Required\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Perceptron, LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "\n",
        "# Digits dataset(d)\n",
        "dig_data = load_digits()\n",
        "X_digits, y_digits = dig_data.data, dig_data.target\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_digits, y_digits, test_size=0.2, random_state=42)\n",
        "\n",
        "# Iris dataset(i)\n",
        "iris_data = pd.read_csv('iris.data')\n",
        "X_iris, y_iris = iris_data.iloc[:, :-1].values, iris_data.iloc[:, 4].values\n",
        "encoder = LabelEncoder()\n",
        "y_iris_encoded = encoder.fit_transform(y_iris)\n",
        "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(X_iris, y_iris_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Classifiers\n",
        "classifier_pipelines = {\n",
        "    \"Perceptron\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', Perceptron(max_iter=1000, tol=1e-6))\n",
        "    ]),\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', LogisticRegression(max_iter=1000, solver='liblinear'))\n",
        "    ]),\n",
        "    \"Linear SVM\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', SVC(kernel=\"linear\"))\n",
        "    ]),\n",
        "    \"Non-linear SVM (RBF)\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', SVC(kernel=\"rbf\"))\n",
        "    ]),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"KNN\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', KNeighborsClassifier())\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Tuning hyperparameters\n",
        "tuning_params = {\n",
        "    \"Perceptron\": {'model__alpha': [0.0001, 0.001, 0.01, 0.1], 'model__eta0': [0.01, 0.1, 1]},\n",
        "    \"Logistic Regression\": {'model__C': [0.01, 0.1, 1, 10, 100]},\n",
        "    \"Linear SVM\": {'model__C': [0.1, 1, 10, 100]},\n",
        "    \"Non-linear SVM (RBF)\": {'model__C': [0.1, 1, 10, 100]},\n",
        "}\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(classifier_name, pipeline, X_train, X_test, y_train, y_test, params=None):\n",
        "    start_time = time.time()\n",
        "    if params:\n",
        "        model = GridSearchCV(pipeline, params, cv=5)\n",
        "        model.fit(X_train, y_train)\n",
        "        best_params = model.best_params_\n",
        "    else:\n",
        "        model = pipeline\n",
        "        model.fit(X_train, y_train)\n",
        "        best_params = \"None\"\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
        "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "    print(f\"{classifier_name}:\\n\"\n",
        "          f\"  This is Training Accuracy: {accuracy_train:.4f}\\n\"\n",
        "          f\"  This is Testing Accuracy: {accuracy_test:.4f}\\n\"\n",
        "          f\"  This is Training Time: {training_time:.4f} sec\\n\"\n",
        "          f\"  This is Best Parameter: {best_params}\\n\")\n",
        "\n",
        "# Evaluating for Digits Dataset\n",
        "print(\"Evaluating for Digits Dataset\")\n",
        "for name, pipe in classifier_pipelines.items():\n",
        "    params = tuning_params.get(name, None)\n",
        "    evaluate_model(name, pipe, X_train_d, X_test_d, y_train_d, y_test_d, params)\n",
        "\n",
        "# Evaluating for Iris Dataset\n",
        "print(\"\\nEvaluating for Iris Dataset\")\n",
        "for name in [\"Logistic Regression\", \"Non-linear SVM (RBF)\", \"Decision Tree\"]:\n",
        "    pipe = classifier_pipelines[name]\n",
        "    params = tuning_params.get(name, None)\n",
        "    evaluate_model(name, pipe, X_train_i, X_test_i, y_train_i, y_test_i, params)"
      ]
    }
  ]
}