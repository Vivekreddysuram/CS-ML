# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I56TDEkO5sovroByrxulXU9VTwEfmjRl
"""

import numpy as np

class Perceptron:
    def __init__(self, learning_rate=0.01, epochs=50):
        self.learning_rate = learning_rate
        self.epochs = epochs

    def fit(self, X, y):
        self.weights = np.zeros(1 + X.shape[1])
        self.errors = []

        for _ in range(self.epochs):
            error = 0
            for xi, target in zip(X, y):
                update = self.learning_rate * (target - self.predict(xi))
                self.weights[1:] += update * xi
                self.weights[0] += update
                error += int(update != 0.0)
            self.errors.append(error)
        return self

    def net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

class Adaline:
    def __init__(self, learning_rate=0.01, epochs=50):
        self.learning_rate = learning_rate
        self.epochs = epochs

    def fit(self, X, y):
        self.weights = np.zeros(1 + X.shape[1])
        self.costs = []

        for _ in range(self.epochs):
            output = self.net_input(X)
            errors = (y - output)
            self.weights[1:] += self.learning_rate * X.T.dot(errors)
            self.weights[0] += self.learning_rate * errors.sum()
            cost = (errors**2).sum() / 2.0
            self.costs.append(cost)
        return self

    def net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

class SGD:
    def __init__(self, learning_rate=0.01, epochs=50, shuffle=True, random_state=None):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.shuffle = shuffle
        self.random_state = random_state
        if random_state:
            np.random.seed(random_state)

    def fit(self, X, y):
        self.weights = np.zeros(1 + X.shape[1])
        self.costs = []

        for _ in range(self.epochs):
            if self.shuffle:
                X, y = self._shuffle(X, y)
            cost = []
            for xi, target in zip(X, y):
                update = self.learning_rate * (target - self.predict(xi))
                self.weights[1:] += update * xi
                self.weights[0] += update
                cost.append(0.5 * (update ** 2))
            avg_cost = sum(cost) / len(y)
            self.costs.append(avg_cost)
        return self

    def partial_fit(self, X, y):
        if not hasattr(self, 'weights'):
            self.weights = np.zeros(1 + X.shape[1])
        for xi, target in zip(X, y):
            update = self.learning_rate * (target - self.predict(xi))
            self.weights[1:] += update * xi
            self.weights[0] += update
        return self

    def _shuffle(self, X, y):
        r = np.random.permutation(len(y))
        return X[r], y[r]

    def net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time

class Perceptron:
    def __init__(self, eta=0.01, n_iter=10, random_state=1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state
        self.accuracies = []  # Initialize list to store accuracies

    def fit(self, X, y):
        rgen = np.random.RandomState(self.random_state)
        self.weights = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])
        self.errors_ = []

        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                update = self.eta * (target - self.predict(xi))
                self.weights[1:] += update * xi
                self.weights[0] += update
                errors += int(update != 0.0)
            self.errors_.append(errors)
            accuracy = self.calculate_accuracy(X, y)  # Calculating accuracy after each iteration
            self.accuracies.append(accuracy)
        return self

    def net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

    def calculate_accuracy(self, X, y):
        predictions = np.where(np.dot(X, self.weights[1:]) + self.weights[0] >= 0.0, 1, -1)
        accuracy = np.mean(predictions == y)
        return accuracy

def load_data(file_path):
    if file_path == 'iris.data':
        data = pd.read_csv('iris.data', header=None)
        X = data.iloc[0:100, [0,2]].values
        y = data.iloc[0:100, 4].values
        y = np.where(y == 'Iris-setosa', -1, 1)
    elif file_path == 'buddymove_holidayiq.csv':
        data = pd.read_csv('buddymove_holidayiq.csv')
        X = data.iloc[:, 1:].values
        y = data.iloc[:, 0].values
        y = np.where(y == 'User 1', -1, 1)
    else:
        raise ValueError("Invalid file path.")
    return X, y

def plot_updates(updates, data_file, iterations):
    plt.figure(figsize=(8, 6))
    plt.plot(range(1, len(updates) + 1), updates, marker='o')
    plt.xlabel('Iteration')
    plt.ylabel('number of errors')
    plt.title(f'number of errors vs. Iteration - {data_file}, Iterations: {iterations}')
    plt.grid(True)
    plt.show()

def main():
    data_files = ['iris.data', 'buddymove_holidayiq.csv']

    for data_file in data_files:
        X, y = load_data(data_file)
        clf = Perceptron(eta=0.1, n_iter=10)
        st_time=time.time()
        clf.fit(X, y)
        ed_time=time.time()
        accuracy = clf.calculate_accuracy(X, y)
        print(f"Iterations for {data_file}: {clf.n_iter}, number of errors: {sum(clf.errors_)}")
        plot_updates(clf.errors_, data_file, clf.n_iter)

        for i, acc in enumerate(clf.accuracies, start=1):
            print(f"Iteration {i}: Accuracy = {acc*100:.2f}%")

        print("Total time took to execute ",ed_time-st_time)

if __name__ == "__main__":
    main()

"""adaline"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

class Adaline:
    def __init__(self, eta=0.00001, n_iter=1000, tolerance=1e-6):
        self.eta = eta
        self.n_iter = n_iter
        self.tolerance = tolerance
        self.iterations = 0

    def fit(self, X, y):
        X_normalized = self._normalize(X)
        self.weights = np.zeros(X_normalized.shape[1] + 1)
        self.cost_history = []
        for epoch in range(self.n_iter):
            net_input = self.net_input(X_normalized)
            errors = y - net_input
            self.weights[1:] += self.eta * X_normalized.T.dot(errors)
            self.weights[0] += self.eta * errors.sum()
            cost = np.mean(errors**2) / 2
            self.cost_history.append(cost)
            if epoch > 0 and abs(self.cost_history[-1] - self.cost_history[-2]) < self.tolerance:
                break
            self.iterations += 1
        return self

    def net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def predict(self, X):
        X_normalized = self._normalize(X)
        return np.where(self.net_input(X_normalized) >= 0.0, 1, -1)

    def _normalize(self, X):
        X_normalized = (X - X.mean(axis=0)) / X.std(axis=0)
        return X_normalized

def load_data(file_path):
    if file_path == 'iris.data':
        data = pd.read_csv('iris.data', header=None)
        X = data.iloc[0:100, [0,2]].values
        y = data.iloc[0:100, 4].values
        y = np.where(y == 'Iris-setosa', -1, 1)
    elif file_path == 'buddymove_holidayiq.csv':
        data = pd.read_csv('buddymove_holidayiq.csv')
        X = data.iloc[:, 1:].values
        y = data.iloc[:, 0].values
        y = np.where(y == 'User 1', -1, 1)
    else:
        raise ValueError("Invalid file path.")
    return X, y

def plot_updates(cost_history, data_file, iterations):
    plt.figure(figsize=(8, 6))
    plt.plot(range(len(cost_history)), cost_history, marker='o')
    plt.xlabel('Iteration')
    plt.ylabel('Cost')
    plt.title(f'Cost vs. Iteration - {data_file}, Iterations: {iterations}')
    plt.grid(True)
    plt.show()

def calculate_accuracy(X, y, weights):
    predictions = np.where(np.dot(X, weights[1:]) + weights[0] >= 0.0, 1, -1)
    accuracy = (predictions == y).mean() * 100
    return accuracy

def main():
    data_files = ['iris.data', 'buddymove_holidayiq.csv']

    for data_file in data_files:
        X, y = load_data(data_file)
        clf = Adaline(eta=0.00001, n_iter=1000, tolerance=1e-6)
        st_time=time.time()
        clf.fit(X, y)
        ed_time=time.time()
        accuracy = calculate_accuracy(X, y, clf.weights)
        print(f"Iterations for {data_file}: {clf.iterations}, Accuracy: {accuracy}%")
        print(f"Costs for {data_file}: {clf.cost_history}")


        print("Total time took to execute ",ed_time-st_time)
        plot_updates(clf.cost_history, data_file, clf.iterations)

if __name__ == "__main__":
    main()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time

class SimpleSGDClassifier:
    def __init__(self, learning_rate=0.0001, epochs=10, shuffle=True, random_state=None, regularization=0.0001):
        self.lr = learning_rate
        self.epochs = epochs
        self.shuffle = shuffle
        self.random_state = random_state
        self.regularization = regularization
        self.weights_initialized = False
        self.cost_history = []
        self.accuracies = []

    def fit(self, X, y):
        X_normalized = self._normalize(X)
        self._initialize_weights(X_normalized.shape[1])
        self.cost_history = []
        self.accuracies = []

        for i in range(self.epochs):
            if self.shuffle:
                X_normalized, y = self._shuffle(X_normalized, y)
            costs = []
            for xi, target in zip(X_normalized, y):
                costs.append(self._update_weights(xi, target))
            avg_cost = np.mean(costs)
            self.cost_history.append(avg_cost)
            accuracy = self.calculate_accuracy(X, y)
            self.accuracies.append(accuracy)  # Storing accuracy for each iteration
            self.lr /= (1 + self.regularization * i)  # Learning rate decay
        return self

    def partial_fit(self, X, y):
        if not self.weights_initialized:
            X_normalized = self._normalize(X)
            self._initialize_weights(X_normalized.shape[1])
        if y.ravel().shape[0] > 1:
            for xi, target in zip(X_normalized, y):
                self._update_weights(xi, target)
        else:
            self._update_weights(X_normalized, y)
        return self

    def _initialize_weights(self, m):
        self.rgen = np.random.RandomState(self.random_state)
        self.weights = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)
        self.weights_initialized = True

    def _shuffle(self, X, y):
        r = self.rgen.permutation(len(y))
        return X[r], y[r]

    def _normalize(self, X):
        X_normalized = (X - X.mean(axis=0)) / X.std(axis=0)
        return X_normalized

    def _net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def _activation(self, X):
        return self._net_input(X)

    def _update_weights(self, xi, target):
        output = self._activation(xi)
        error = (target - output)
        self.weights[1:] += self.lr * (xi.dot(error) - self.regularization * self.weights[1:])  # Regularization
        self.weights[0] += self.lr * error
        cost = 0.5 * np.sum(error**2)
        return cost

    def predict(self, X):
        X_normalized = self._normalize(X)
        return np.where(self._net_input(X_normalized) >= 0.0, 1, -1)

    def calculate_accuracy(self, X, y):
        predictions = self.predict(X)
        accuracy = np.mean(predictions == y) * 100
        return accuracy

def load_data(file_path):
    if file_path == 'iris.data':
        data = pd.read_csv('iris.data', header=None)
        X = data.iloc[0:100, [0, 2]].values
        y = data.iloc[0:100, 4].values
        y = np.where(y == 'Iris-setosa', -1, 1)
        learning_rate = 0.01
        epochs = 10
    elif file_path == 'buddymove_holidayiq.csv':
        data = pd.read_csv('buddymove_holidayiq.csv')
        X = data.iloc[:, 1:].values
        y = data.iloc[:, 0].values
        y = np.where(y == 'User 1', -1, 1)
        learning_rate = 0.001
        epochs = 10
    else:
        raise ValueError("Invalid file path.")
    return X, y, learning_rate, epochs

def plot_cost_history(cost_history, data_file, epochs):
    plt.figure(figsize=(8, 6))
    plt.plot(range(1, len(cost_history) + 1), cost_history, marker='o')
    plt.xlabel('Epoch')
    plt.ylabel('Cost')
    plt.title(f'Cost vs. Epoch - {data_file}, Epochs: {epochs}')
    plt.grid(True)
    plt.show()

def main():
    data_files = ['iris.data', 'buddymove_holidayiq.csv']

    for data_file in data_files:
        X, y, learning_rate, epochs = load_data(data_file)
        clf = SimpleSGDClassifier(learning_rate=learning_rate, epochs=epochs)
        st_time=time.time()
        clf.fit(X, y)
        ed_time=time.time()

        print(f"Iterations for {data_file}:")
        for i, acc in enumerate(clf.accuracies, start=1):
            print(f"Iteration {i}: Accuracy = {acc:.2f}%")

        accuracy = clf.accuracies[-1]
        print(f"Epochs for {data_file}: {clf.epochs}, Final Accuracy: {accuracy:.2f}%")
        plot_cost_history(clf.cost_history, data_file, clf.epochs)
        print("Total time took to execute ",ed_time-st_time)

if __name__ == "__main__":
    main()

"""7th"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time

class SGDClassifier:
    def __init__(self, eta=0.01, n_iter=10):
        self.eta = eta
        self.n_iter = n_iter

    def fit(self, X, y):
        self.weights = np.zeros(1 + X.shape[1])
        self.errors_ = []
        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                update = self.eta * (target - self.predict(xi))
                self.weights[1:] += update * xi
                self.weights[0] += update
                errors += int(update != 0.0)
            self.errors_.append(errors)
        return self

    def net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

class OneVsRestClassifier:
    def __init__(self, base_classifier):
        self.base_classifier = base_classifier
        self.classifiers = {}

    def fit(self, X, y):
        self.classes_ = np.unique(y)
        for c in self.classes_:
            self.classifiers[c] = self.base_classifier()
            y_binary = np.where(y == c, 1, -1)
            self.classifiers[c].fit(X, y_binary)

    def predict(self, X):
        preds = []
        for x in X:
            class_scores = {c: self.classifiers[c].predict(x) for c in self.classes_}
            pred = max(class_scores, key=class_scores.get)
            preds.append(pred)
        return np.array(preds)

def load_iris():
    iris_data = pd.read_csv('iris.data', header=None)

    X = iris_data.iloc[0:150,[0,2]].values
    y = iris_data.iloc[0:150,4].values
    y = np.where(y == 'Iris-setosa', 1, np.where(y == 'Iris-Versicolor', -1, -1))
    return X, y

def load_customer():
    customer_data = pd.read_csv('buddymove_holidayiq.csv')
    X = customer_data.iloc[:, 1:].values
    y = customer_data.iloc[:, 0].values
    y = np.where(y == 'User 1', -1, 1)
    return X, y

def plot_errors_over_iterations(errors, n_iter_max, dataset_name):
    plt.plot(range(1, n_iter_max + 1), errors, marker='o')
    plt.xlabel('Iteration')
    plt.ylabel('number of errors')
    plt.title(f'number of errors Over Iterations - {dataset_name}')
    plt.grid(True)
    plt.show()

def calculate_accuracy(X, y, classifier):
    preds = classifier.predict(X)
    accuracy = np.mean(preds == y) * 100
    return accuracy

def main():
    datasets = [('iris.data', 0.01, 100), ('buddymove_holidayiq.csv', 0.001, 1000)]

    for dataset, eta, n_iter in datasets:
        X, y = load_iris() if dataset == 'iris.data' else load_customer()

        ovr_classifier = OneVsRestClassifier(SGDClassifier)
        ovr_classifier.fit(X, y)

        errors = []
        n_iter_max = 0
        for c in ovr_classifier.classes_:
            errors.append(ovr_classifier.classifiers[c].errors_)
            n_iter_max = max(n_iter_max, len(ovr_classifier.classifiers[c].errors_))

        plot_errors_over_iterations(errors[0], n_iter_max, dataset.capitalize())
        accuracy = calculate_accuracy(X, y, ovr_classifier)
        print(f"{dataset.capitalize()} Dataset - Final Accuracy: {accuracy:.2f}%")

        # Iterations code snippet
        print("Iterations for", dataset.capitalize())
        for i, class_errors in enumerate(errors):
            print(f"Class {i + 1}:")
            for iter_num, num_updates in enumerate(class_errors, start=1):
                print(f"Iteration {iter_num}: Number of errors = {num_updates}")
            print()

if __name__ == "__main__":
    main()

"""Classifier3"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
st_time=time.time()



class SGDClassifier:
    def __init__(self, eta=0.01, n_iter=10):
        self.eta = eta
        self.n_iter = n_iter

    def fit(self, X, y):
        self.weights = np.zeros(1 + X.shape[1])
        self.errors_ = []
        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                update = self.eta * (target - self.predict(xi))
                self.weights[1:] += update * xi
                self.weights[0] += update
                errors += int(update != 0.0)
            self.errors_.append(errors)
        return self

    def net_input(self, X):
        return np.dot(X, self.weights[1:]) + self.weights[0]

    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

class OneVsRestClassifier:
    def __init__(self, base_classifier):
        self.base_classifier = base_classifier
        self.classifiers = {}

    def fit(self, X, y):
        self.classes_ = np.unique(y)
        for c in self.classes_:
            self.classifiers[c] = self.base_classifier()
            y_binary = np.where(y == c, 1, -1)
            self.classifiers[c].fit(X, y_binary)

    def predict(self, X):
        preds = []
        for x in X:
            class_scores = {c: self.classifiers[c].predict(x) for c in self.classes_}
            pred = max(class_scores, key=class_scores.get)
            preds.append(pred)
        return np.array(preds)

class Classifier3:
    def fit(self, X, y):
        pass

    def predict(self, X):
        return np.where(X[:, 1] == 2, 1, -1)  #

def load_iris():
    iris_data = pd.read_csv('iris.data', header=None)

    X = iris_data.iloc[0:150,[0,2]].values
    y = iris_data.iloc[0:150,4].values

    y = np.where(y == 'Iris-setosa', 1, np.where(y == 'Iris-Versicolor', 2, 3))
    return X, y

def load_customer():
    customer_data = pd.read_csv('buddymove_holidayiq.csv')
    X = customer_data.iloc[:, 1:].values
    y = customer_data.iloc[:, 0].values
    return X, y

def plot_errors_over_iterations(errors, n_iter_max, dataset_name):
    plt.plot(range(1, n_iter_max + 1), errors, marker='o')
    plt.xlabel('Iteration')
    plt.ylabel('number of errors')
    plt.title(f'number of errors Over Iterations - {dataset_name}')
    plt.grid(True)
    plt.show()

def calculate_accuracy(X, y, classifier):
    preds = classifier.predict(X)
    accuracy = np.mean(preds == y) * 100
    return accuracy

def main():
    datasets = [('iris.data', 0.01, 100), ('buddymove_holidayiq.csv', 0.001, 1000)]

    for dataset, eta, n_iter in datasets:
        X, y = load_iris() if dataset == 'iris.data' else load_customer()

        if dataset == 'iris.data':
            classifier = Classifier3()
        else:
            classifier = OneVsRestClassifier(SGDClassifier)
        classifier.fit(X, y)

        errors = []
        n_iter_max = 0
        if isinstance(classifier, OneVsRestClassifier):
            for c in classifier.classes_:
                errors.append(classifier.classifiers[c].errors_)
                n_iter_max = max(n_iter_max, classifier.classifiers[c].n_iter)
            plot_errors_over_iterations(errors[0], n_iter_max, dataset.capitalize())
        ed_time=time.time()
        accuracy = calculate_accuracy(X, y, classifier)
        print(f"{dataset.capitalize()} Dataset - Final Accuracy: {accuracy:.2f}%")
        if isinstance(classifier, OneVsRestClassifier):
            print(f"number of errors: {errors[0][-1]}")
        print("Total time took to execute ",ed_time-st_time)

if __name__ == "__main__":
    main()